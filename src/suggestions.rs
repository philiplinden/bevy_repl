use bevy::prelude::*;
use crate::repl::ReplState;

pub(crate) struct ReplSuggestionsPlugin;

impl Plugin for ReplSuggestionsPlugin {
    fn build(&self, app: &mut App) {
        app.init_resource::<ReplPredictionsCache>()
        .add_systems(Startup, init_suggestions);
    }
}

#[derive(Resource, Default)]
pub(crate) struct ReplSuggestions {
    suggestion_index: Option<usize>,
}

#[derive(Resource)]
pub struct ReplPredictionsCache {
    /// Trie used for completions, autogenerated from registered console commands
    /// this probably should operate over references to save memory, but this is convenient for now
    pub(crate) commands_trie: Option<trie_rs::Trie<u8>>,
    pub(crate) predictions_hash_key: Option<u64>,
    pub(crate) predictions_cache: Vec<String>,
    pub(crate) prediction_matches_buffer: bool,
}

impl Default for ReplPredictionsCache {
    fn default() -> Self {
        Self {
            commands_trie: None,
            predictions_hash_key: None,
            predictions_cache: Vec::new(),
            prediction_matches_buffer: false,
        }
    }
}

/// builds the predictive search engine for completions
fn init_suggestions(config: Res<ReplConfig>, mut cache: ResMut<ReplPredictionsCache>) {
    let mut trie_builder = trie_rs::TrieBuilder::new();
    for cmd in config.commands.keys() {
        trie_builder.push(cmd);

    for completions in &config.arg_completions {
        trie_builder.push(completions.join(" "));
    }

    cache.commands_trie = Some(trie_builder.build());
}}

/// Recompute predictions for the console based on the current buffer content.
/// if the buffer does not change the predictions are not recomputed.
pub(crate) fn recompute_predictions(
    state: &mut ReplState,
    cache: &mut ReplPredictionsCache,
    suggestion_count: usize,
) {
    if state.buf.is_empty() {
        cache.predictions_cache.clear();
        cache.predictions_hash_key = None;
        cache.prediction_matches_buffer = false;
        state.suggestion_index = None;
        return;
    }

    let hash = FixedState::with_seed(42).hash_one(&state.buf);

    let recompute = if let Some(predictions_hash_key) = cache.predictions_hash_key {
        predictions_hash_key != hash
    } else {
        true
    };

    if recompute {
        let words = Shlex::new(&state.buf).collect::<Vec<_>>();
        let query = words.join(" ");

        let suggestions = match &cache.commands_trie {
            Some(trie) if !query.is_empty() => trie
                .predictive_search(query)
                .into_iter()
                .take(suggestion_count)
                .collect(),
            _ => vec![],
        };
        cache.predictions_cache = suggestions
            .into_iter()
            .map(|s| String::from_utf8(s).unwrap_or_default())
            .collect();

        cache.predictions_hash_key = Some(hash);
        state.suggestion_index = None;
        cache.prediction_matches_buffer = false;

        if let Some(first) = cache.predictions_cache.first() {
            if cache.predictions_cache.len() == 1 && first == &state.buf {
                cache.prediction_matches_buffer = true
            }
        }
    }
}
